{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe6ec701",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, Lambda, Dense, Flatten\n",
    "from keras.models import Model\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.applications.resnet import preprocess_input\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3813a1d9",
   "metadata": {},
   "source": [
    "# Re-size all the images to this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810473be",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [224, 224]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16256fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'E:\\\\content\\\\Data\\\\dataset\\\\train\\\\'\n",
    "valid_path = 'E:\\\\content\\\\Data\\\\dataset\\\\test\\\\'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c55f8d11",
   "metadata": {},
   "source": [
    "#  add preprocessing layer to the front of Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d8fa9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet50(input_shape=IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93efd69c",
   "metadata": {},
   "source": [
    " # don't train existing weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d048df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in resnet.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d8ffb",
   "metadata": {},
   "source": [
    "# # useful for getting number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3daf43a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = glob('E:\\\\content\\\\Data\\\\dataset\\\\train\\\\*')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1a86cb",
   "metadata": {},
   "source": [
    "# # our layers - you can add more if you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fec272fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Flatten()(resnet.output)\n",
    "# x = Dense(1000, activation='relu')(x)\n",
    "prediction = Dense(len(folders), activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e965767c",
   "metadata": {},
   "source": [
    "# # create a model object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c30bf46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=resnet.input, outputs=prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9feb87",
   "metadata": {},
   "source": [
    "# # view the structure of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97ec5476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 100352)       0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 4)            401412      flatten[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,989,124\n",
      "Trainable params: 401,412\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c217d3",
   "metadata": {},
   "source": [
    "# # tell the model what cost and optimization method to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba2ee791",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer='adam',\n",
    "  metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09e23c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dce0a3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d559da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6bc23642",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6326 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('E:\\\\content\\\\Data\\\\dataset\\\\train\\\\',\n",
    "                                                 target_size = (224, 224),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81e042dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 771 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set = test_datagen.flow_from_directory('E:\\\\content\\\\Data\\\\dataset\\\\test\\\\',\n",
    "                                            target_size = (224, 224),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d892c7",
   "metadata": {},
   "source": [
    "# # fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a0edddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d0e6a71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "198/198 [==============================] - 350s 2s/step - loss: 1.3016 - accuracy: 0.6459 - val_loss: 0.8155 - val_accuracy: 0.6628\n",
      "Epoch 2/100\n",
      "198/198 [==============================] - 221s 1s/step - loss: 0.8279 - accuracy: 0.7276 - val_loss: 0.8003 - val_accuracy: 0.7069\n",
      "Epoch 3/100\n",
      "198/198 [==============================] - 210s 1s/step - loss: 0.6132 - accuracy: 0.7964 - val_loss: 0.4509 - val_accuracy: 0.8340\n",
      "Epoch 4/100\n",
      "198/198 [==============================] - 210s 1s/step - loss: 0.4889 - accuracy: 0.8255 - val_loss: 0.7763 - val_accuracy: 0.7289\n",
      "Epoch 5/100\n",
      "198/198 [==============================] - 203s 1s/step - loss: 0.5277 - accuracy: 0.8201 - val_loss: 0.8112 - val_accuracy: 0.6874\n",
      "Epoch 6/100\n",
      "198/198 [==============================] - 205s 1s/step - loss: 0.5591 - accuracy: 0.8206 - val_loss: 0.5658 - val_accuracy: 0.7899\n",
      "Epoch 7/100\n",
      "198/198 [==============================] - 191s 962ms/step - loss: 0.4943 - accuracy: 0.8310 - val_loss: 0.5934 - val_accuracy: 0.7860\n",
      "Epoch 8/100\n",
      "198/198 [==============================] - 194s 978ms/step - loss: 0.5556 - accuracy: 0.8174 - val_loss: 0.8973 - val_accuracy: 0.6965\n",
      "Epoch 9/100\n",
      "198/198 [==============================] - 188s 948ms/step - loss: 0.5417 - accuracy: 0.8312 - val_loss: 0.4640 - val_accuracy: 0.8236\n",
      "Epoch 10/100\n",
      "198/198 [==============================] - 187s 946ms/step - loss: 0.4612 - accuracy: 0.8463 - val_loss: 0.5064 - val_accuracy: 0.8132\n",
      "Epoch 11/100\n",
      "198/198 [==============================] - 194s 978ms/step - loss: 0.4739 - accuracy: 0.8433 - val_loss: 0.9748 - val_accuracy: 0.7302\n",
      "Epoch 12/100\n",
      "198/198 [==============================] - 227s 1s/step - loss: 0.4278 - accuracy: 0.8573 - val_loss: 0.8743 - val_accuracy: 0.7328\n",
      "Epoch 13/100\n",
      "198/198 [==============================] - 217s 1s/step - loss: 0.4897 - accuracy: 0.8375 - val_loss: 0.5540 - val_accuracy: 0.7977\n",
      "Epoch 14/100\n",
      "198/198 [==============================] - 197s 995ms/step - loss: 0.4315 - accuracy: 0.8634 - val_loss: 0.6111 - val_accuracy: 0.8119\n",
      "Epoch 15/100\n",
      "198/198 [==============================] - 203s 1s/step - loss: 0.5989 - accuracy: 0.8261 - val_loss: 0.6952 - val_accuracy: 0.7977\n",
      "Epoch 16/100\n",
      "198/198 [==============================] - 209s 1s/step - loss: 0.4026 - accuracy: 0.8655 - val_loss: 0.5043 - val_accuracy: 0.8262\n",
      "Epoch 17/100\n",
      "198/198 [==============================] - 199s 1s/step - loss: 0.3595 - accuracy: 0.8767 - val_loss: 1.7295 - val_accuracy: 0.6680\n",
      "Epoch 18/100\n",
      "198/198 [==============================] - 225s 1s/step - loss: 0.4911 - accuracy: 0.8565 - val_loss: 0.8008 - val_accuracy: 0.7562\n",
      "Epoch 19/100\n",
      "198/198 [==============================] - 259s 1s/step - loss: 0.4335 - accuracy: 0.8618 - val_loss: 0.5350 - val_accuracy: 0.8301\n",
      "Epoch 20/100\n",
      "198/198 [==============================] - 223s 1s/step - loss: 0.4636 - accuracy: 0.8685 - val_loss: 1.3564 - val_accuracy: 0.6913\n",
      "Epoch 21/100\n",
      "198/198 [==============================] - 209s 1s/step - loss: 0.4712 - accuracy: 0.8579 - val_loss: 0.4661 - val_accuracy: 0.8431\n",
      "Epoch 22/100\n",
      "198/198 [==============================] - 217s 1s/step - loss: 0.5541 - accuracy: 0.8490 - val_loss: 1.7267 - val_accuracy: 0.6680\n",
      "Epoch 23/100\n",
      "198/198 [==============================] - 202s 1s/step - loss: 0.4058 - accuracy: 0.8718 - val_loss: 0.5144 - val_accuracy: 0.8353\n",
      "Epoch 24/100\n",
      "198/198 [==============================] - 204s 1s/step - loss: 0.4403 - accuracy: 0.8655 - val_loss: 0.5405 - val_accuracy: 0.8275\n",
      "Epoch 25/100\n",
      "198/198 [==============================] - 208s 1s/step - loss: 0.3818 - accuracy: 0.8767 - val_loss: 0.4030 - val_accuracy: 0.8534\n",
      "Epoch 26/100\n",
      "198/198 [==============================] - 226s 1s/step - loss: 0.4371 - accuracy: 0.8626 - val_loss: 1.0940 - val_accuracy: 0.7237\n",
      "Epoch 27/100\n",
      "198/198 [==============================] - 227s 1s/step - loss: 0.4874 - accuracy: 0.8516 - val_loss: 0.9631 - val_accuracy: 0.7471\n",
      "Epoch 28/100\n",
      "198/198 [==============================] - 212s 1s/step - loss: 0.4296 - accuracy: 0.8683 - val_loss: 2.1652 - val_accuracy: 0.6757\n",
      "Epoch 29/100\n",
      "198/198 [==============================] - 205s 1s/step - loss: 0.5137 - accuracy: 0.8620 - val_loss: 0.9481 - val_accuracy: 0.7458\n",
      "Epoch 30/100\n",
      "198/198 [==============================] - 239s 1s/step - loss: 0.4004 - accuracy: 0.8775 - val_loss: 0.6166 - val_accuracy: 0.8145\n",
      "Epoch 31/100\n",
      "198/198 [==============================] - 227s 1s/step - loss: 0.5524 - accuracy: 0.8449 - val_loss: 0.5010 - val_accuracy: 0.8444\n",
      "Epoch 32/100\n",
      "198/198 [==============================] - 220s 1s/step - loss: 0.3979 - accuracy: 0.8770 - val_loss: 0.8756 - val_accuracy: 0.7691\n",
      "Epoch 33/100\n",
      "198/198 [==============================] - 195s 986ms/step - loss: 0.4061 - accuracy: 0.8808 - val_loss: 0.3842 - val_accuracy: 0.8716\n",
      "Epoch 34/100\n",
      "198/198 [==============================] - 191s 966ms/step - loss: 0.4551 - accuracy: 0.8645 - val_loss: 0.4001 - val_accuracy: 0.8651\n",
      "Epoch 35/100\n",
      "198/198 [==============================] - 208s 1s/step - loss: 0.3402 - accuracy: 0.8933 - val_loss: 0.4336 - val_accuracy: 0.8625\n",
      "Epoch 36/100\n",
      "198/198 [==============================] - 230s 1s/step - loss: 0.4212 - accuracy: 0.8770 - val_loss: 0.9218 - val_accuracy: 0.7782\n",
      "Epoch 37/100\n",
      "198/198 [==============================] - 212s 1s/step - loss: 0.5260 - accuracy: 0.8603 - val_loss: 0.6038 - val_accuracy: 0.8249\n",
      "Epoch 38/100\n",
      "198/198 [==============================] - 171s 863ms/step - loss: 0.3896 - accuracy: 0.8859 - val_loss: 0.4773 - val_accuracy: 0.8262\n",
      "Epoch 39/100\n",
      "198/198 [==============================] - 148s 749ms/step - loss: 0.4679 - accuracy: 0.8770 - val_loss: 0.6598 - val_accuracy: 0.8106\n",
      "Epoch 40/100\n",
      "198/198 [==============================] - 141s 712ms/step - loss: 0.4056 - accuracy: 0.8901 - val_loss: 0.6522 - val_accuracy: 0.7951\n",
      "Epoch 41/100\n",
      "198/198 [==============================] - 138s 698ms/step - loss: 0.4099 - accuracy: 0.8758 - val_loss: 0.4067 - val_accuracy: 0.8599\n",
      "Epoch 42/100\n",
      "198/198 [==============================] - 141s 712ms/step - loss: 0.4292 - accuracy: 0.8786 - val_loss: 0.7855 - val_accuracy: 0.8016\n",
      "Epoch 43/100\n",
      "198/198 [==============================] - 141s 711ms/step - loss: 0.5563 - accuracy: 0.8568 - val_loss: 0.5927 - val_accuracy: 0.8314\n",
      "Epoch 44/100\n",
      "198/198 [==============================] - 144s 729ms/step - loss: 0.3744 - accuracy: 0.8882 - val_loss: 1.0139 - val_accuracy: 0.7782\n",
      "Epoch 45/100\n",
      "198/198 [==============================] - 139s 704ms/step - loss: 0.4272 - accuracy: 0.8797 - val_loss: 0.4772 - val_accuracy: 0.8495\n",
      "Epoch 46/100\n",
      "198/198 [==============================] - 156s 789ms/step - loss: 0.3774 - accuracy: 0.8870 - val_loss: 0.4876 - val_accuracy: 0.8470\n",
      "Epoch 47/100\n",
      "198/198 [==============================] - 149s 750ms/step - loss: 0.4394 - accuracy: 0.8731 - val_loss: 1.7684 - val_accuracy: 0.7056\n",
      "Epoch 48/100\n",
      "198/198 [==============================] - 151s 763ms/step - loss: 0.4799 - accuracy: 0.8724 - val_loss: 0.3771 - val_accuracy: 0.8703\n",
      "Epoch 49/100\n",
      "198/198 [==============================] - 155s 785ms/step - loss: 0.4246 - accuracy: 0.8770 - val_loss: 0.4090 - val_accuracy: 0.8547\n",
      "Epoch 50/100\n",
      "198/198 [==============================] - 161s 815ms/step - loss: 0.5062 - accuracy: 0.8620 - val_loss: 0.7285 - val_accuracy: 0.8223\n",
      "Epoch 51/100\n",
      "198/198 [==============================] - 158s 799ms/step - loss: 0.4728 - accuracy: 0.8683 - val_loss: 0.6835 - val_accuracy: 0.8106\n",
      "Epoch 52/100\n",
      "198/198 [==============================] - 160s 806ms/step - loss: 0.3651 - accuracy: 0.8944 - val_loss: 0.3782 - val_accuracy: 0.8677\n",
      "Epoch 53/100\n",
      "198/198 [==============================] - 161s 814ms/step - loss: 0.3922 - accuracy: 0.8886 - val_loss: 0.5677 - val_accuracy: 0.8236\n",
      "Epoch 54/100\n",
      "198/198 [==============================] - 256s 1s/step - loss: 0.3438 - accuracy: 0.8998 - val_loss: 0.6315 - val_accuracy: 0.8197\n",
      "Epoch 55/100\n",
      "198/198 [==============================] - 146s 737ms/step - loss: 0.3810 - accuracy: 0.8898 - val_loss: 0.8015 - val_accuracy: 0.8016\n",
      "Epoch 56/100\n",
      "198/198 [==============================] - 135s 683ms/step - loss: 0.3723 - accuracy: 0.8955 - val_loss: 0.4825 - val_accuracy: 0.8547\n",
      "Epoch 57/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198/198 [==============================] - 135s 682ms/step - loss: 0.4315 - accuracy: 0.8832 - val_loss: 1.9032 - val_accuracy: 0.6835\n",
      "Epoch 58/100\n",
      "198/198 [==============================] - 135s 680ms/step - loss: 0.6163 - accuracy: 0.8528 - val_loss: 0.6584 - val_accuracy: 0.8418\n",
      "Epoch 59/100\n",
      "198/198 [==============================] - 135s 683ms/step - loss: 0.3275 - accuracy: 0.9029 - val_loss: 1.1315 - val_accuracy: 0.7536\n",
      "Epoch 60/100\n",
      "198/198 [==============================] - 135s 684ms/step - loss: 0.3327 - accuracy: 0.9034 - val_loss: 0.4895 - val_accuracy: 0.8612\n",
      "Epoch 61/100\n",
      "198/198 [==============================] - 135s 683ms/step - loss: 0.3249 - accuracy: 0.9050 - val_loss: 0.9479 - val_accuracy: 0.7756\n",
      "Epoch 62/100\n",
      "198/198 [==============================] - 136s 686ms/step - loss: 0.4845 - accuracy: 0.8663 - val_loss: 0.4853 - val_accuracy: 0.8651\n",
      "Epoch 63/100\n",
      "198/198 [==============================] - 135s 682ms/step - loss: 0.3535 - accuracy: 0.8974 - val_loss: 0.4525 - val_accuracy: 0.8742\n",
      "Epoch 64/100\n",
      "198/198 [==============================] - 135s 684ms/step - loss: 0.4801 - accuracy: 0.8816 - val_loss: 1.8563 - val_accuracy: 0.7069\n",
      "Epoch 65/100\n",
      "198/198 [==============================] - 135s 681ms/step - loss: 0.3519 - accuracy: 0.8938 - val_loss: 1.3206 - val_accuracy: 0.7250\n",
      "Epoch 66/100\n",
      "198/198 [==============================] - 135s 682ms/step - loss: 0.3439 - accuracy: 0.9023 - val_loss: 0.6154 - val_accuracy: 0.8405\n",
      "Epoch 67/100\n",
      "198/198 [==============================] - 135s 683ms/step - loss: 0.3355 - accuracy: 0.8968 - val_loss: 0.9292 - val_accuracy: 0.7730\n",
      "Epoch 68/100\n",
      "198/198 [==============================] - 135s 682ms/step - loss: 0.4657 - accuracy: 0.8750 - val_loss: 1.4793 - val_accuracy: 0.7250\n",
      "Epoch 69/100\n",
      "198/198 [==============================] - 135s 682ms/step - loss: 0.3914 - accuracy: 0.8938 - val_loss: 0.6109 - val_accuracy: 0.8482\n",
      "Epoch 70/100\n",
      "198/198 [==============================] - 135s 683ms/step - loss: 0.3706 - accuracy: 0.8963 - val_loss: 0.4195 - val_accuracy: 0.8586\n",
      "Epoch 71/100\n",
      "198/198 [==============================] - 135s 681ms/step - loss: 0.3784 - accuracy: 0.8914 - val_loss: 0.6277 - val_accuracy: 0.8314\n",
      "Epoch 72/100\n",
      "198/198 [==============================] - 135s 684ms/step - loss: 0.3125 - accuracy: 0.9116 - val_loss: 0.4428 - val_accuracy: 0.8677\n",
      "Epoch 73/100\n",
      "198/198 [==============================] - 135s 680ms/step - loss: 0.3044 - accuracy: 0.9077 - val_loss: 0.8479 - val_accuracy: 0.7990\n",
      "Epoch 74/100\n",
      "198/198 [==============================] - 135s 683ms/step - loss: 0.3793 - accuracy: 0.8984 - val_loss: 0.4945 - val_accuracy: 0.8547\n",
      "Epoch 75/100\n",
      "198/198 [==============================] - 135s 683ms/step - loss: 0.4008 - accuracy: 0.8882 - val_loss: 0.5792 - val_accuracy: 0.8534\n",
      "Epoch 76/100\n",
      "198/198 [==============================] - 135s 681ms/step - loss: 0.3829 - accuracy: 0.8909 - val_loss: 0.4089 - val_accuracy: 0.8755\n",
      "Epoch 77/100\n",
      "198/198 [==============================] - 135s 682ms/step - loss: 0.4819 - accuracy: 0.8827 - val_loss: 0.4438 - val_accuracy: 0.8716\n",
      "Epoch 78/100\n",
      "198/198 [==============================] - 135s 682ms/step - loss: 0.6939 - accuracy: 0.8538 - val_loss: 0.4615 - val_accuracy: 0.8729\n",
      "Epoch 79/100\n",
      "198/198 [==============================] - 135s 681ms/step - loss: 0.4263 - accuracy: 0.8887 - val_loss: 0.4969 - val_accuracy: 0.8625\n",
      "Epoch 80/100\n",
      "198/198 [==============================] - 135s 682ms/step - loss: 0.3393 - accuracy: 0.9071 - val_loss: 0.5993 - val_accuracy: 0.8470\n",
      "Epoch 81/100\n",
      "198/198 [==============================] - 135s 681ms/step - loss: 0.3024 - accuracy: 0.9105 - val_loss: 0.4245 - val_accuracy: 0.8768\n",
      "Epoch 82/100\n",
      "198/198 [==============================] - 135s 682ms/step - loss: 0.3315 - accuracy: 0.9048 - val_loss: 0.9903 - val_accuracy: 0.7730\n",
      "Epoch 83/100\n",
      "198/198 [==============================] - 135s 683ms/step - loss: 0.3728 - accuracy: 0.8949 - val_loss: 0.4870 - val_accuracy: 0.8418\n",
      "Epoch 84/100\n",
      "198/198 [==============================] - 136s 685ms/step - loss: 0.3870 - accuracy: 0.8944 - val_loss: 0.3610 - val_accuracy: 0.8885\n",
      "Epoch 85/100\n",
      "198/198 [==============================] - 135s 682ms/step - loss: 0.3952 - accuracy: 0.8969 - val_loss: 0.9737 - val_accuracy: 0.7873\n",
      "Epoch 86/100\n",
      "198/198 [==============================] - 135s 683ms/step - loss: 0.3355 - accuracy: 0.9036 - val_loss: 0.7205 - val_accuracy: 0.8288\n",
      "Epoch 87/100\n",
      "198/198 [==============================] - 999s 5s/step - loss: 0.3997 - accuracy: 0.8972 - val_loss: 0.7754 - val_accuracy: 0.8301\n",
      "Epoch 88/100\n",
      "198/198 [==============================] - 209s 1s/step - loss: 0.4333 - accuracy: 0.8865 - val_loss: 0.6488 - val_accuracy: 0.8392\n",
      "Epoch 89/100\n",
      "198/198 [==============================] - 137s 692ms/step - loss: 0.3813 - accuracy: 0.9047 - val_loss: 0.9207 - val_accuracy: 0.7899\n",
      "Epoch 90/100\n",
      "198/198 [==============================] - 137s 692ms/step - loss: 0.4726 - accuracy: 0.8840 - val_loss: 1.4850 - val_accuracy: 0.7173\n",
      "Epoch 91/100\n",
      "198/198 [==============================] - 136s 688ms/step - loss: 0.3388 - accuracy: 0.9050 - val_loss: 0.8636 - val_accuracy: 0.8003\n",
      "Epoch 92/100\n",
      "198/198 [==============================] - 137s 690ms/step - loss: 0.3318 - accuracy: 0.9031 - val_loss: 0.4118 - val_accuracy: 0.8794\n",
      "Epoch 93/100\n",
      "198/198 [==============================] - 137s 689ms/step - loss: 0.2897 - accuracy: 0.9143 - val_loss: 0.4404 - val_accuracy: 0.8768\n",
      "Epoch 94/100\n",
      "198/198 [==============================] - 137s 690ms/step - loss: 0.4149 - accuracy: 0.8936 - val_loss: 0.5871 - val_accuracy: 0.8210\n",
      "Epoch 95/100\n",
      "198/198 [==============================] - 137s 691ms/step - loss: 0.3629 - accuracy: 0.9023 - val_loss: 0.4317 - val_accuracy: 0.8794\n",
      "Epoch 96/100\n",
      "198/198 [==============================] - 136s 688ms/step - loss: 0.5328 - accuracy: 0.8756 - val_loss: 0.5799 - val_accuracy: 0.8327\n",
      "Epoch 97/100\n",
      "198/198 [==============================] - 136s 686ms/step - loss: 0.3920 - accuracy: 0.8946 - val_loss: 0.5834 - val_accuracy: 0.8366\n",
      "Epoch 98/100\n",
      "198/198 [==============================] - 136s 689ms/step - loss: 0.3969 - accuracy: 0.8960 - val_loss: 0.4928 - val_accuracy: 0.8599\n",
      "Epoch 99/100\n",
      "198/198 [==============================] - 137s 690ms/step - loss: 0.3249 - accuracy: 0.9082 - val_loss: 1.2390 - val_accuracy: 0.7639\n",
      "Epoch 100/100\n",
      "198/198 [==============================] - 137s 691ms/step - loss: 0.3182 - accuracy: 0.9083 - val_loss: 1.1501 - val_accuracy: 0.7665\n"
     ]
    }
   ],
   "source": [
    "r = model.fit_generator(\n",
    "  training_set,\n",
    "  validation_data=test_set,\n",
    "  epochs=100,\n",
    "  steps_per_epoch=len(training_set),\n",
    "  validation_steps=len(test_set)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33d30573",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shubh\\anaconda3\\envs\\tensorflow_gpuenv\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('resnet50.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "451cc3c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('resnet.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1342aa7",
   "metadata": {},
   "source": [
    "# #Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3522407c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['loss'], label='train loss')\n",
    "plt.plot(r.history['val_loss'], label='val loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('LossVal_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a76f9d",
   "metadata": {},
   "source": [
    "# #Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6ab1c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(r.history['acc'], label='train acc')\n",
    "plt.plot(r.history['val_acc'], label='val acc')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "plt.savefig('AccVal_acc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
